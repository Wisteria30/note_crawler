YANS 2023 @浅草橋 参加報告

こんにちは。
PKSHA Technology という会社でアルゴリズムエンジニアをしている福地成彦です。
弊社は、2023 年 8 月 29〜31 日に東京都台東区浅草橋で行われたNLP若手の会 (YANS) 第18回シンポジウムに、スポンサーブース（プラチナスポンサー）とポスター 2 件で参加しました。
このブログ記事では、4 年ぶりに現地開催された YANS で印象に残ったことや、弊社の発表の一部を振り返りたいと思います。
福地 成彦 | AI Solution事業本部 アルゴリズムエンジニア東京大学大学院情報理工学系研究科数理情報学専攻 修士課程を修了。
大学院では、深層学習による文のベクトル空間への埋め込みを研究。
その後、新卒で PKSHA Technology に入社。
マーケティングやコールセンター領域における自然言語処理アルゴリズムの開発プロジェクト、顧客接点領域の対話分類や文埋め込みモデルの R&D 等に従事。
YANS 2023 についてYANS は、学部〜若手（30 代）を中心とした自然言語処理研究者やエンジニアの交流コミュニティで、毎年夏にシンポジウムを開催しています。
コロナ禍以前のシンポジウムでは、泊まり込みの合宿形式でかなり濃い交流をしていたようですが、近年はオンラインでの開催となっていました。
しかし、今年のシンポジウムは 4 年ぶりのオフライン開催。
会場である浅草橋ヒューリックホールは熱気と興奮に包まれていました。
PKSHAのスポンサーセッションの様子今年の主なコンテンツは以下の通りです。
ハッカソンチュートリアルポスター発表ラウンドテーブルスポンサーセッション招待ポスターセッション若手の研究者・技術者の交流を目標の一つにしている学会というだけあり、チーム制のハッカソンやラウンドテーブル、ポスター形式での招待セッションなど、一般的な学会ではあまり設定されないようなコンテンツが目立ちました。
特にラウンドテーブルは、「埋め込み表現」といった技術トピックから「エンジニアのキャリア」のような進路の話題など、幅広いトピックに対し 4〜6 人で話合うもので、初対面同士でも交流を深めるのに非常に良い機会だと感じました。
YANS 分野交流ハッカソン with 言語処理学会 30 周年記念事業毎年恒例の YANS ハッカソンが今年も開催されました。
今年は「YANS 分野交流ハッカソン with 言語処理学会 30 周年記念事業」と題され、参加人数や規模が拡大されていました。
今年は「デモアプリハッカソン」と「リーダーボードハッカソン」の二種目あり、ランダムに割り振られた 5〜6 名のチームの対抗戦が行われました。
初対面のメンバーと協力して開発を進めていくので、「分野交流ハッカソン」の名前の通り絶好の機会になりました。
また、デモアプリハッカソン／リーダーボードハッカソンの両方で、OpenAI API の使用がレギュレーションで定められており、LLMの盛り上がりを肌で感じることができました。
いずれのハッカソンもオフライン開催で開発時間も 4 時間だったので、濃密な熱気が会場にあふれていました。
私も参加していたのですが、久しぶりにアドレナリンが限界まで分泌されていた気がします。
デモアプリハッカソン最近の NLP の状況をキャッチアップしていると、Hugging Face Spaces で LLM などのデモを触ることも多いのではないでしょうか。
デモアプリハッカソンは、Hugging Face Spaces のような LLM デモアプリを 4 時間で作成するコンペティションでした。
OpenAI API で裏側の言語生成を行い、Hugging Face から提供されている Gradio というツールを用いて UI を作成することが、このハッカソンの基本構成となっています。
このハッカソンの一番の特色は、LLM だけでなく他のモダリティも組み合わせたマルチモーダルなデモアプリを作成する必要があるという点です。
特に、画像生成と LLM を組み合わせ、ユニークで斬新なアプリの開発に取り組むチームが多く、非常に刺激的でした。
リーダーボードハッカソンLLM を使って質の良いインターネット広告文を生成するにはどのようなプロンプティングが必要なのでしょうか。
このハッカソンでは、検索サービスのクエリと広告ランディングページのテキストから、適切な検索結果ページの広告タイトルを生成するというタスク (*1 ) を 6 チームで競い、最終評価では会場の参加者によるライブ人手評価を行いました。
私もこのコンペティションに参加したので、一参加者としての目線でハッカソンのポイント・解法の論点を挙げてみます。
運営から、学習データと few-shot in-context learning (*2 ) のベースラインコードが提供されていましたが、これらをどの程度踏襲するのがよいのかがポイントになります。
人手評価で高スコアを獲得するためには、few-shot learning で学習データに似た広告文を生成するものと、 zero-shot (*3 ) プロンプティングで学習データを無視した広告文を生成するものとどちらが良い結果になるのかについて、チームごとに方針が分かれていました。
評価データセットによる BLEU スコアや ROUGE スコアに基づく自動評価リーダーボードが用意されていましたが、人手評価とリーダーボードが相関するかは自明ではありません（評価データの広告文の質が高いものでない場合、むしろ人手評価とリーダーボード逆相関する可能性がある）。
最終的な評価で私のチームは 3 位でした。
1 位：few-shot leaning2 位：学習データを捨てて自作データで few-shot learning3 位：多段 zero-shot learning上位の 3 チームの方針を見ると、few-shot, zero-shot が混在しており、学習データの活用度合いに多様性がありました。
上位解法が単一手法に収束しないという点でも、ハッカソンのタスクや難易度が丁寧に設計されているという印象を受けました。
運営の皆様、本当にありがとうございました。
実は、few-shot vs zero-shot という対立の外に fine-tune (*4 ) というダークホースがいました。
あるチームは、OpenAI APIのfine-tuning 機能を利用して、GPT3.5 を学習し、五七五の俳句の形式で広告文を生成していました。
GPT3.5 の fine-tuning 機能はハッカソンの 1 週間前に公開されたばかりだったので、NLP 業界のスピード感を改めて感じることができました。
(*1) 広告文生成タスクの規定とベンチマーク構築. 三田ら. 2023(*2) few-shot in-context leaning : 大規模言語モデル（以下、LLM）のプロンプトに、生成したいタスクの入力・出力の例をいくつか例示することで、所望の出力を生成させる方法。
例えば、入力文に対して感情分析をする際に、「入力に対してポジティブかネガティブを判断してください。
例) 今日も元気: ポジティブ, お腹がいたい: ネガティブ, 睡眠不足: ポジティブ, お皿が割れた: ネガティブ」というプロンプトを使うイメージです。
(*3) zero-shot learning : few-shot に対して、生成したいタスクの入力・出力の例をいくつか例示しない方法。
例えば、入力文に対して感情分析をする際に、入力に対してポジティブかネガティブを判断してください。
」のみを入力する方法。
(*4) fine-tune : 事前学習済みのモデルにターゲットタスクの比較的少数のデータを学習させて、重みパラメータをターゲットタスクが解けるように更新すること。
ポスター発表YANS のシンポジウムと言えば、始めたての研究でも受け入れてくれる懐の深いポスター発表。
今回は、前回の 2 倍以上となる 140 件の発表がありました。
PKSHA からは、「LoRA を用いた大規模多言語文埋め込みモデルの構築」と「2 段階対照学習による日本語文埋め込みモデルの汎用性獲得」の 2 件を発表しました。
全体的なポスターの内容を見ると、LLM のパラダイムの浸透をひしひしと感じました。
例えば、「翻訳」というワードをタイトルに含む発表は 140 件中 7 件で、前回の 6 件/ 68 件と比較して割合が半減していました。
逆に、「大規模言語モデル」や「大規模事前学習モデル」「LLM」というフレーズを含む研究が 140 件中 21 件と、前年の 68 件中 2 件から爆発的な増加傾向をみせました。
NLP2023 で「ChatGPT で自然言語処理は終わるのか？」という緊急セッションが開催されてから半年も経たないない間に、自然言語処理の研究のメインストリームが急速に LLM へと移っていることが鮮明に感じられました。
弊社から発表した 2 件の発表は以下です。
LoRA を用いた大規模多言語文埋め込みモデルの構築 [矢野ら]本発表は、弊社で長期インターンをしている矢野さんの研究です。
矢野さんポスター発表の様子多言語文埋め込みモデルは、単一の文埋め込みのモデルで複数言語の文を同じ意味空間に埋め込みます。
チャットボットや検索をグローバル展開していく場合、性能の良い多言語文埋め込みモデルが必要となります。
多言語文埋め込みに関する先行研究では、自然言語推論（NLI）データに基づいた効率的な学習の有効性が示されていますが、言語モデルの大規模化に伴う性能への影響については十分に調査されていませんでした。
本発表では、単言語モデルである Sentence T5 を多言語 NLI を利用して多言語に拡張した Multilingual Sentence T5 を提案しました。
モデルの訓練には LLM を低計算リソースで学習することができる LoRA を採用し、57 億パラメータまでモデルサイズを拡張しました。
複数の評価実験で提案手法は NLI ベースの既存手法を上回り、さらに提案手法のモデルサイズと性能の間に正の相関があることを確認しました。
本研究は、全 20 件の奨励賞の一つに選出いただきました。
奨励賞受賞2 段階対照学習による日本語文埋め込みモデルの汎用性獲得 [福地ら]最近の LLM ブームの中で、テキスト埋め込みによるベクトル検索を LLM と組み合わせることは多いのではないでしょうか。
テキスト埋め込みをベクトル検索をに用いる場合には、意味的類似性タスクだけでなく関連性検索タスクでも性能が高い「汎用日本語文埋め込みモデル」が必要です。
本研究では、多様なデータによる 2 段階の対照学習によって汎用性を指向した日本語文埋め込みモデル：GLuCoSE（General LUke-based COntrastive Sentence Embedding）を構築しました。
実験の結果、提案モデルが意味的類似性、検索タスクとも OpenAI ada を上回るスコアを記録しました。
このモデルは YANS 開催中に商用利用可能なライセンスで公開しました。
YANS2023 NLP若手の会 (YANS) 第18回シンポジウムにて大規模言語モデル活用を加速する2つの成果を発表、一部成果のモデルを公開プレスリリースより💡NLPモデル「GLuCoSE」リリースのお知らせ以前公開した「pkshatech/simcse-ja-bert-base-clcmlp」に引き続き、日本語のテキスト埋め込みモデルを公開しました。
検索や意味的類似度計算など幅広く商用利用が可能です。
他モデルとの性能比較もぜひご覧ください。
https://t.co/vsveiS4ct1— PKSHA採用担当 (@PKSHA_saiyo) August 30, 2023
今回、弊社から発表した発表 2 件は、偶然にもテキスト埋め込みの研究でした。
とはいえ、弊社がテキスト埋め込みの研究ばかりをしているわけではありません。
自然言語処理・LLM を社会実装するために、基礎的な研究からパートナー企業との共同プロジェクトまで幅広い研究開発を日々進めています。
また、弊社からスポンサー賞を授与した発表は以下の 1 件です。
おめでとうございます。
敵対的事例を用いた In-context learning による LLM 生成エッセイの検出 [小池ら]大規模言語モデル（LLM）の社会への普及が進み、文章を作成する際にも LLM を活用することが盛んになりつつあります。
しかし、LLM の出力を使用することは、意図しない著作物の剽窃や誤情報を流布してしまうなどのリスクも考えられます。
このような背景から、LLM による文章を検出する手法が提案されているものの、文の言い換えなどのアタックにより検出性能が低下することが報告されています。
この研究では、LLM 文章の検出器が間違えやすいようなアタックを意図的に行い、そのアタック結果を検出器が再考慮することで、より頑健な検出器が実現できることを提案しています。
エッセイ文を用いた実験の結果、既存手法より検出性能を低下させやすいアタックを実現することで、既存の検出手法を大幅に上回る検出ができていることを主張しています。
本研究の動機が LLM の社会実装におけるリスクを見据えており、高性能な検出手法が提案できていることや、アタックにより人間に近い文章が生成されやすいといった分析が大変興味深く、弊社からスポンサー賞を贈呈させていただきました。
PKSHA の Vision である“共進化”の掛け声でサイコロを投げ、副賞を選ぶ小池さん「せーのっ！共〜進化！」全体の感想4 年ぶりに対面開催となった「NLP 若手の会 第 18 回シンポジウム」に参加し、LLM という NLP 業界に留まらない大きな流れと、その流れを更に加速させようとしている若手研究者・エンジニアの熱量を、各コンテンツの節々で感じることができました。
ハッカソンでは、OpenAI API を使用したハッカソンということで、以前の fine-tuning がメインのハッカソンから大きく開発の方法が変わりました。
また、初の試みとなるデモアプリハッカソンが開催されましたが、4 時間で言語生成と画像生成を組み合わせるなど、前回の現地開催であった4年前では SF のような非現実的な話だったでしょう。
ポスターセッションでも、発表件数に減少傾向が見られる研究分野もある一方で、LLM 関連の評価やセキュリティ、応用研究の数が増えてきていました。
1 年という短い期間で様変わりした NLP 業界の進化のスピードを感じます。
来年の YANS では、どのような研究テーマが発展し、どのような応用事例が登場するのでしょうか… すでに来年の YANS が楽しみです！最後に、久方ぶりのオンサイト開催や参加者の急増などの大変な状況のなか、参加者同士はもちろん、参加者とスポンサー間の交流も促進された素晴らしいシンポジウムを運営してくださった委員の皆様に、改めて感謝申し上げます。
PKSHA スポンサーブース株式会社 PKSHA Technology では、自然言語処理技術を含むアルゴリズムを社会に実装していく仲間を募集しています！NLP 関連の研究開発に従事されてきた方はもちろん、社会実装に興味を持つ若手の方も、新卒入社や長期インターンなどで活躍されています。
ご興味のある方は、是非各種サイトよりご応募いただけると幸いです。
▼ 25 新卒：アルゴリズムエンジニア（データサイエンティスト）本選考はこちら



hrmos.co


25年新卒_アルゴリズムエンジニア本選考（PKSHAグループ）



株式会社PKSHA Technology



東京都文京区 ほか0箇所




フルタイム










募集要項をみる






▼ 25 新卒：アルゴリズムエンジニア（データサイエンティスト）インターンはこちら



hrmos.co


長期就業型インターンシップ（PKSHAグループ）



株式会社PKSHA Technology



東京都文京区 ほか0箇所




インターン










募集要項をみる






▼アルゴリズムエンジニア【 NLP 】



hrmos.co


アルゴリズムエンジニア【NLP】



株式会社PKSHA Technology



 ほか0箇所




フルタイム










募集要項をみる






▼カジュアル面談も受付中です！Wantedly はこちら


株式会社PKSHA Technologyの会社情報 - Wantedly


株式会社PKSHA Technologyの魅力を伝えるコンテンツと、住所や代表・従業員などの会社情報です。
私たちは人が作る


www.wantedly.com