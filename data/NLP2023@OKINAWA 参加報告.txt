NLP2023@OKINAWA 参加報告

こんにちは！PKSHA Technologyでアルゴリズムエンジニアをしています、星野悠一郎です。
2023.3.13〜17に沖縄にて開催された言語処理学会第29回年次大会 (NLP2023)に弊社はプラチナスポンサーとして、アルゴリズムエンジニアの渡邉、福地、星野、人事/広報の内藤の計4名で参加してきました。
この記事では、星野と福地を中心に振り返りをしたいと思います。
沖縄コンベンションセンター入口星野 悠一郎 | AI Solution事業本部 アルゴリズムエンジニア早稲田大学大学院 先進理工学研究科 物理学及応用物理学専攻 博士後期課程単位取得退学、先進理工学部 助手。
その間、主に重力理論における非線形現象の研究、画像認識/ 強化学習を用いた量子物理の研究に従事。
新卒としてPKSHA Technology へ参画後は文法誤り訂正や質問応答技術の研究開発・プロジェクト等に従事。
福地 成彦 | AI Solution事業本部 アルゴリズムエンジニア東京大学大学院情報理工学系研究科数理情報学専攻 修士課程を修了。
大学院では、深層学習による文のベクトル空間への埋め込みを研究。
その後、PKSHA Technologyに新卒入社。
マーケティングやコールセンター領域における自然言語処理アルゴリズムの開発プロジェクト、顧客接点領域の対話分類や文埋め込みモデルのR&D等に従事。
大会概要今年は沖縄コンベンションセンターで開催されました。
オンラインとオフラインのハイブリッドで実施され、2019年以来のオフライン開催でした。
今大会は過去最高の参加人数となったそうです。
 NLP2023 入口参加人数・全参加者 1,828人（※参加登録者）・NLP2023 発表論文数：579件NLP言語処理学会 年次大会統計データまた、発表数が過去最多というだけでなく、学会中には Chat-GPTに関する緊急パネルディスカッション 「緊急パネル：ChatGPTで自然言語処理は終わるのか？」も企画され、さらにその翌日には OpenAI から GPT-4 が発表されるなど、非常にタイムリーで情報量の多い学会になりました。
（私は、自然言語処理学会初参加だったのですが、間違いなく記憶に残るものになりました。
）そして、企業スポンサーということで以下のようなブースを構えていました。
ブースの様子PKSHAの事業紹介PKSHAで行っているR&D活動の一例個人的には、学生さんが複数名ブースに遊びに来てくれて、研究の議論や交流ができたことが嬉しかったです。
去年福地さんと参加した質問応答のコンペ「AI王」のことを知ってくださっていたり、コンペに参加していた学生さんとお話しすることができ、このような活動を通じて、PKSHAのことを知ってくれる学生が少しでも増えると良いなと思いました。
PKSHAでは普段から職種や役職の垣根なく、より良い社会実装のために議論することが日常的に行われており、来てくださった学生さんたちにも、その雰囲気を少しでも体感いただけたのではないかと感じています。

また、交流会にて、AI王で上位に入賞したチームの方達ともリアルで顔を合わせて話すことができ、久しぶりのオフライン学会でのコミュニケーションはやはり良いなと再認識できました。
（ちなみに、この時の話をきっかけに AI王運営委員会の公認イベントとして入賞チームによる「AI王」振り返り会が開催されることになりました。
）研究紹介過去最多となる研究発表があった中で、PKSHAの参加メンバーが特に興味を持った面白そうな研究を、いくつか簡単に紹介したいと思います。
[A5-4] ニューラル記号推論における推論過程の教示方法 LLMの出現によって、常識・数量・記号等に関する推論タスクの性能が劇的に向上してきており、盛んに研究されてるようになりました。
その中で、思考の連鎖 (Chain-of-Thought) など、推論の結果のみならずその導出過程も含めて生成することの有効性が報告されています。
本研究では、タスク遂行においてどのような推論過程の出力方法および探索方法を取ることで高い性能が得られるかについて報告されています。
思考の連鎖のように一遍に導出過程を出力するよりも、ステップを踏んでモデルに生成させること、また最短経路で導出するよりも、導出すべきものを全て出力したり、求めたいものから逆算して後ろ向きに導出する方法の有効性が示されており、大変興味深い内容でした。
[H6-2] マルチエージェント強化学習に基づく共同作業を自律的に行う対話システムの最適化巨大言語モデルによって対話能力が劇的に向上する中で、人と協調してタスクを遂行することが可能なシステムの実現に向けた研究が盛んにおこなわれています。
本研究では、説得対話にフォーカスし、被説得者の発話有無に依存せずに説得対話を遂行する対話エージェントの実現を目指しています。
タスク設定として、マルチエージェントの対話を想定、発話内容の自然さ、冗長性、タスク達成できたかどうか、という複数の観点で対話を評価した上で、強化学習によってより説得性を高める対話モデルの構築を狙っています。
結果として、まだ課題は残っているものの説得性という観点においては既存手法を上回るなど有望な結果が得られており、今後の研究の発展に期待したいと思いました。
[Q8-4] コンテキストの量が質問応答モデルのショートカット推論に与える影響について本研究では、生成型の Open-Domain QA モデルのデファクトスタンダードである FiD がコンテキストとして与えられる文章の量によってどのような影響を受けるかを調査しています。
 FiD は質問への回答に不要な文章（negative passage）が多くなるほど正答率が低下すること, 主にモデルの推論に悪影響を与えやすいのはその中でも一部の hard negative passage であること等が報告されています。
特に興味深い点は、そのような hard negative の半数は正答に矛盾する情報を含まず、別解の存在を示唆するものでも無かったという、本来質問応答モデルが無視するべきパッセージだということです。
本研究の結果は、encoder-decoder モデルに対してのものですが、GPT-3をはじめとする大規模言語モデルでの振舞いも気になるところですLangChain や Llamaindex の登場により、手軽に検索＆生成を試せるようになっていると思いますが、場合によっては検索した文章の取り扱いに注意しなくてはいけないということを示唆しているかもしれません。
引き続き、関連研究も注視していきたいと思います。
[Q8-10] 大規模言語モデルに基づく 複数の外部ツールを利用した推論フレームワークChatGPTを使っているときに、計算ミスや専門知識不足で誤った回答をされたなんていう経験をした方は多いのではないでしょうか？ChatGPTを代表とする大規模言語モデルは、膨大な数のwebや書籍を学習していますが、専門知識や数値計算が必要なタスクでは推論性能が低いと認識されてきました。
この研究では、NumGLUE Task2という化学の専門知識を要する数値計算タスクをGPT-3に解かせるために、電卓や化学反応予測器、モル質量検索器などの外部ツールをGPT-3の生成途中で呼び出すという手法を提案しています。
具体的には、問題文、Chain-of-Thought の指示(“Let’s think step by step.”)、外部ツールの使い方20事例、の3つの要素をプロンプトとしてGPT-3に与えて回答生成を行っています。
結果として、外部ツールなしの場合と比べて28.0%(ツールなし: 57.85%→ツールあり: 85.85%)のスコア向上が報告されていました。
ポスターでお話をうかがったところ発表者は学部4年生ということでした。
最近は、ToolformerやART(Automatic Reasoning and Tool-use)、ChatGPT PluginなどのLLM×外部ツールの研究が盛り上がっていますが、それらと同時期に同様のアイデアを学部4年生が発表しているということにとても驚き関心しました。
LLMと外部ツールの連携は、様々なアルゴリズムモジュールを保有するPKSHAにとって重要な技術なので、今後も関連研究に注目していきます。
感想・最後にコンベンションセンターの建物、お天気は曇りや小雨でした今回、自然言語処理学会には初参加だったこともあり、いろいろと勝手が分からなく不安な部分もありましたが、slackを中心に現地情報やセッションの誘導・資料共有など様々な情報が頻繁に共有されており、研究発表の聴講や参加者との交流を円滑に行えました。
送迎バスやキッチンカーまで手配されていたのも非常に助かりました。
多くの参加者との交流を通じて、普段あまり触れていない研究内容についても知ることができ、大変刺激的でした。
また、学会前日には乾先生や鈴木先生はじめとする第一線で活躍されている方々と一緒に夕食を共にすることができ、非常に貴重なお話も聞くことができました。
今後は、大学やコミュニティとの関係もより一層強化できたらと思います。
改めて、このような素敵な学会を運営していただいた運営委員の皆様、交流していただいた参加者の方々に感謝申し上げます。
次回は神戸で開催ということで、来年度も是非参加したいです！長くなってしまいましたが、最後に PKSHA Technologyでは、機械学習を含めたアルゴリズムを一緒に社会に実装してくれる仲間を募集しています。
自然言語処理を長年研究してきた方はもちろん、情報系以外出身で社会人から自然言語処理の研究を始めた方、研究よりもKagglerなどコンペ中心にスキルを磨いている方など様々な人たちが活躍しています。
研究で培ってきた技術やコンペなどで身につけた技術を社会に実装することにご興味がある方は、Wantedlyや採用サイトから応募が可能ですので、是非ご覧ください！▼アルゴリズムエンジニア（データサイエンス）インターンはこちら



hrmos.co


長期就業型インターンシップ（PKSHAグループ）



株式会社PKSHA Technology



東京都文京区 ほか0箇所




インターン










募集要項をみる






▼採用職種一覧


株式会社PKSHA Technology


株式会社PKSHA Technology です。
| HRMOS


hrmos.co



▼Wantedlyはこちら


株式会社PKSHA Technologyの会社情報 - Wantedly


株式会社PKSHA Technologyの魅力を伝えるコンテンツと、住所や代表・従業員などの会社情報です。
私たちは人が作る


www.wantedly.com